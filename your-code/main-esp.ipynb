{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Índice de contenidos\n",
    "1. Antes de empezar:\n",
    "\n",
    "2. Reto 1 - Importar y describir el conjunto de datos\n",
    "\n",
    "    2.0.0.1 Explore el conjunto de datos con técnicas matemáticas y de visualización. ¿Qué encuentra?\n",
    "\n",
    "3. Reto 2 - Limpieza y transformación de datos\n",
    "\n",
    "4. Reto 3 - Preprocesamiento de datos\n",
    "\n",
    "    4.0.0.1 Utilizaremos el StandardScaler de sklearn.preprocessing y escalaremos nuestros datos. Lea más sobre StandardScaler aquí.\n",
    "\n",
    "5. Reto 4 - Agrupación de datos con K-Means\n",
    "\n",
    "6. Reto 5 - Agrupación de datos con DBSCAN\n",
    "\n",
    "7. Reto 6 - Comparar K-Means con DBSCAN\n",
    "\n",
    "8. Reto adicional 2 - Cambiar el número de clusters de K-Means\n",
    "\n",
    "9. Bonus Challenge 3 - Cambiar DBSCAN eps y min_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Antes de empezar:\n",
    "- Lee el archivo README.md\n",
    "- Comenta todo lo que puedas y utiliza los recursos del archivo README.md\n",
    "- ¡Feliz aprendizaje!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your libraries:\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings                                              \n",
    "from sklearn.exceptions import DataConversionWarning          \n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafío 1 - Importar y describir el conjunto de datos\n",
    "\n",
    "En este laboratorio, utilizaremos un conjunto de datos que contiene información sobre las preferencias de los clientes. Analizaremos cuánto gasta cada cliente en un año en cada subcategoría de la tienda de comestibles e intentaremos encontrar similitudes mediante la agrupación.\n",
    "\n",
    "El origen del conjunto de datos es [aquí](https://archive.ics.uci.edu/ml/datasets/wholesale+customers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "      <th>Region</th>\n",
       "      <th>Fresh</th>\n",
       "      <th>Milk</th>\n",
       "      <th>Grocery</th>\n",
       "      <th>Frozen</th>\n",
       "      <th>Detergents_Paper</th>\n",
       "      <th>Delicassen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12669</td>\n",
       "      <td>9656</td>\n",
       "      <td>7561</td>\n",
       "      <td>214</td>\n",
       "      <td>2674</td>\n",
       "      <td>1338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7057</td>\n",
       "      <td>9810</td>\n",
       "      <td>9568</td>\n",
       "      <td>1762</td>\n",
       "      <td>3293</td>\n",
       "      <td>1776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6353</td>\n",
       "      <td>8808</td>\n",
       "      <td>7684</td>\n",
       "      <td>2405</td>\n",
       "      <td>3516</td>\n",
       "      <td>7844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13265</td>\n",
       "      <td>1196</td>\n",
       "      <td>4221</td>\n",
       "      <td>6404</td>\n",
       "      <td>507</td>\n",
       "      <td>1788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>22615</td>\n",
       "      <td>5410</td>\n",
       "      <td>7198</td>\n",
       "      <td>3915</td>\n",
       "      <td>1777</td>\n",
       "      <td>5185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>29703</td>\n",
       "      <td>12051</td>\n",
       "      <td>16027</td>\n",
       "      <td>13135</td>\n",
       "      <td>182</td>\n",
       "      <td>2204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>39228</td>\n",
       "      <td>1431</td>\n",
       "      <td>764</td>\n",
       "      <td>4510</td>\n",
       "      <td>93</td>\n",
       "      <td>2346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>14531</td>\n",
       "      <td>15488</td>\n",
       "      <td>30243</td>\n",
       "      <td>437</td>\n",
       "      <td>14841</td>\n",
       "      <td>1867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10290</td>\n",
       "      <td>1981</td>\n",
       "      <td>2232</td>\n",
       "      <td>1038</td>\n",
       "      <td>168</td>\n",
       "      <td>2125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2787</td>\n",
       "      <td>1698</td>\n",
       "      <td>2510</td>\n",
       "      <td>65</td>\n",
       "      <td>477</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>440 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Channel  Region  Fresh   Milk  Grocery  Frozen  Detergents_Paper  \\\n",
       "0          2       3  12669   9656     7561     214              2674   \n",
       "1          2       3   7057   9810     9568    1762              3293   \n",
       "2          2       3   6353   8808     7684    2405              3516   \n",
       "3          1       3  13265   1196     4221    6404               507   \n",
       "4          2       3  22615   5410     7198    3915              1777   \n",
       "..       ...     ...    ...    ...      ...     ...               ...   \n",
       "435        1       3  29703  12051    16027   13135               182   \n",
       "436        1       3  39228   1431      764    4510                93   \n",
       "437        2       3  14531  15488    30243     437             14841   \n",
       "438        1       3  10290   1981     2232    1038               168   \n",
       "439        1       3   2787   1698     2510      65               477   \n",
       "\n",
       "     Delicassen  \n",
       "0          1338  \n",
       "1          1776  \n",
       "2          7844  \n",
       "3          1788  \n",
       "4          5185  \n",
       "..          ...  \n",
       "435        2204  \n",
       "436        2346  \n",
       "437        1867  \n",
       "438        2125  \n",
       "439          52  \n",
       "\n",
       "[440 rows x 8 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/Wholesale customers data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explora el conjunto de datos con técnicas matemáticas y de visualización. ¿Qué encuentras?\n",
    "\n",
    "Lista de comprobación:\n",
    "\n",
    "* ¿Qué significa cada columna?\n",
    "* ¿Hay datos categóricos que convertir?\n",
    "* ¿Hay que eliminar datos que faltan?\n",
    "* Colinealidad de columnas: ¿hay correlaciones altas?\n",
    "* Estadísticas descriptivas: ¿hay que eliminar algún valor atípico?\n",
    "* Distribución de los datos por columnas: ¿está sesgada la distribución?\n",
    "* Etc.\n",
    "\n",
    "Información adicional: Hace más de un siglo, un economista italiano llamado Vilfredo Pareto descubrió que aproximadamente el 20% de los clientes representan el 80% de las ventas minoristas típicas. Esto se denomina [principio de Pareto](https://github.com/ironhack-ds-jcampos/lab-unsupervised-learning-es). Compruebe si este conjunto de datos presenta esta característica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas del conjunto de datos:\n",
      "   Channel  Region  Fresh  Milk  Grocery  Frozen  Detergents_Paper  Delicassen\n",
      "0        2       3  12669  9656     7561     214              2674        1338\n",
      "1        2       3   7057  9810     9568    1762              3293        1776\n",
      "2        2       3   6353  8808     7684    2405              3516        7844\n",
      "3        1       3  13265  1196     4221    6404               507        1788\n",
      "4        2       3  22615  5410     7198    3915              1777        5185\n",
      "\n",
      "Información del conjunto de datos:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 440 entries, 0 to 439\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype\n",
      "---  ------            --------------  -----\n",
      " 0   Channel           440 non-null    int64\n",
      " 1   Region            440 non-null    int64\n",
      " 2   Fresh             440 non-null    int64\n",
      " 3   Milk              440 non-null    int64\n",
      " 4   Grocery           440 non-null    int64\n",
      " 5   Frozen            440 non-null    int64\n",
      " 6   Detergents_Paper  440 non-null    int64\n",
      " 7   Delicassen        440 non-null    int64\n",
      "dtypes: int64(8)\n",
      "memory usage: 27.6 KB\n",
      "None\n",
      "\n",
      "Estadísticas descriptivas:\n",
      "          Channel      Region          Fresh          Milk       Grocery  \\\n",
      "count  440.000000  440.000000     440.000000    440.000000    440.000000   \n",
      "mean     1.322727    2.543182   12000.297727   5796.265909   7951.277273   \n",
      "std      0.468052    0.774272   12647.328865   7380.377175   9503.162829   \n",
      "min      1.000000    1.000000       3.000000     55.000000      3.000000   \n",
      "25%      1.000000    2.000000    3127.750000   1533.000000   2153.000000   \n",
      "50%      1.000000    3.000000    8504.000000   3627.000000   4755.500000   \n",
      "75%      2.000000    3.000000   16933.750000   7190.250000  10655.750000   \n",
      "max      2.000000    3.000000  112151.000000  73498.000000  92780.000000   \n",
      "\n",
      "             Frozen  Detergents_Paper    Delicassen  \n",
      "count    440.000000        440.000000    440.000000  \n",
      "mean    3071.931818       2881.493182   1524.870455  \n",
      "std     4854.673333       4767.854448   2820.105937  \n",
      "min       25.000000          3.000000      3.000000  \n",
      "25%      742.250000        256.750000    408.250000  \n",
      "50%     1526.000000        816.500000    965.500000  \n",
      "75%     3554.250000       3922.000000   1820.250000  \n",
      "max    60869.000000      40827.000000  47943.000000  \n",
      "\n",
      "Valores faltantes por columna:\n",
      "Channel             0\n",
      "Region              0\n",
      "Fresh               0\n",
      "Milk                0\n",
      "Grocery             0\n",
      "Frozen              0\n",
      "Detergents_Paper    0\n",
      "Delicassen          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Primeras filas del conjunto de datos:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nInformación del conjunto de datos:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nEstadísticas descriptivas:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\nValores faltantes por columna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tus observaciones aquí**\n",
    "\n",
    "+ Frozen, Grocery, Milk y Detergents Paper tienen una gran ...\n",
    "+ \n",
    "+ \n",
    "+ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto 2 - Limpieza y transformación de datos\n",
    "\n",
    "Si tu conclusión del reto anterior es que los datos necesitan limpieza/transformación, hazlo en las celdas de abajo. Sin embargo, si su conclusión es que los datos no necesitan ser limpiados o transformados, no dudes en saltarte este reto. Si optas por esta última opción, explica los motivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas categòricas:\n",
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "print(\"Columnas categòricas:\")\n",
    "print(categorical_columns)\n",
    "\n",
    "if len(categorical_columns) > 0:\n",
    "    df = pd.get_dummies(df, columns=categorical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tus observaciones aquí**\n",
    "\n",
    "Se tienen que elimitar registros con datos incompletos y se deben procesar algunas filas con datos demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto 3 - Preprocesamiento de datos\n",
    "\n",
    "Uno de los problemas del conjunto de datos es que los rangos de valores son notablemente diferentes en las distintas categorías (por ejemplo, `Fresh` y `Grocery` en comparación con `Detergents_Paper` y `Delicassen`). Si hiciste esta observación en el primer reto, ¡has hecho un gran trabajo! Esto significa que no sólo has completado las preguntas de bonificación en el anterior laboratorio de Aprendizaje Supervisado, sino que también has investigado en profundidad sobre [*feature scaling*](https://en.wikipedia.org/wiki/Feature_scaling). ¡Sigue trabajando así de bien!\n",
    "\n",
    "Diversos rangos de valores en diferentes características podrían causar problemas en nuestra agrupación. La forma de reducir el problema es mediante el escalado de características. Volveremos a utilizar esta técnica con este conjunto de datos.\n",
    "\n",
    "#### Utilizaremos el `StandardScaler` de `sklearn.preprocessing` y escalaremos nuestros datos. Lee más sobre `StandardScaler` [aquí](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler).\n",
    "\n",
    "*Después de escalar tus datos, asigna los datos transformados a una nueva variable `customers_scale`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Datos escalados:\n",
      "      Fresh      Milk   Grocery    Frozen  Detergents_Paper  Delicassen\n",
      "0  0.052933  0.523568 -0.041115 -0.589367         -0.043569   -0.066339\n",
      "1 -0.391302  0.544458  0.170318 -0.270136          0.086407    0.089151\n",
      "2 -0.447029  0.408538 -0.028157 -0.137536          0.133232    2.243293\n",
      "3  0.100111 -0.624020 -0.392977  0.687144         -0.498588    0.093411\n",
      "4  0.840239 -0.052396 -0.079356  0.173859         -0.231918    1.299347\n"
     ]
    }
   ],
   "source": [
    "# Your import here:\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features = ['Fresh', 'Milk', 'Grocery', 'Frozen', 'Detergents_Paper', 'Delicassen']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "customers_scale = scaler.fit_transform(df[features])\n",
    "\n",
    "customers_scale = pd.DataFrame(customers_scale, columns=features)\n",
    "\n",
    "print(\"\\nDatos escalados:\")\n",
    "print(customers_scale.head())\n",
    "\n",
    "customers_scale.to_csv('customer_preferences_scaled.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto 4 - Agrupación de datos con K-Means\n",
    "\n",
    "Ahora vamos a agrupar los datos con K-Means primero. Inicia el modelo K-Means, luego ajusta tus datos escalados. En los datos devueltos por el método `.fit`, hay un atributo llamado `labels_` que es el número de cluster asignado a cada registro de datos. Lo que puede hacer es asignar estas etiquetas de nuevo a `customers` en una nueva columna llamada `customers['labels']`. Entonces verá los resultados de cluster de los datos originales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos originales con etiquetas de clúster:\n",
      "   Channel  Region  Fresh  Milk  Grocery  Frozen  Detergents_Paper  \\\n",
      "0        2       3  12669  9656     7561     214              2674   \n",
      "1        2       3   7057  9810     9568    1762              3293   \n",
      "2        2       3   6353  8808     7684    2405              3516   \n",
      "3        1       3  13265  1196     4221    6404               507   \n",
      "4        2       3  22615  5410     7198    3915              1777   \n",
      "\n",
      "   Delicassen  labels  \n",
      "0        1338       3  \n",
      "1        1776       0  \n",
      "2        7844       0  \n",
      "3        1788       3  \n",
      "4        5185       1  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "\n",
    "kmeans.fit(customers_scale)\n",
    "\n",
    "df['labels'] = kmeans.labels_\n",
    "\n",
    "print(\"Datos originales con etiquetas de clúster:\")\n",
    "print(df.head())\n",
    "\n",
    "df.to_csv('customer_preferences_with_labels.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viendo el elbow pododríamos escoger 2 como el número de clusters correctos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_customers = df\n",
    "\n",
    "kmeans_2 = KMeans(n_clusters=2).fit(customers_scale)\n",
    "\n",
    "labels = kmeans_2.predict(customers_scale)\n",
    "\n",
    "clusters = kmeans_2.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_customers['Label'] = clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuenta los valores en `labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "3    272\n",
       "0     96\n",
       "1     59\n",
       "2     11\n",
       "4      2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts = df['labels'].value_counts()\n",
    "label_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto 5 - Clustering de datos con DBSCAN\n",
    "\n",
    "Ahora vamos a agrupar los datos utilizando DBSCAN. Utiliza `DBSCAN(eps=0.5)` para iniciar el modelo y, a continuación, ajusta los datos escalados. En los datos devueltos por el método `.fit`, asigna las `labels_` de nuevo a `customers['labels_DBSCAN']`. Ahora tus datos originales tienen dos etiquetas, una de K-Means y la otra de DBSCAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Datos originales con etiquetas de clúster DBSCAN:\n",
      "   Channel  Region  Fresh  Milk  Grocery  Frozen  Detergents_Paper  \\\n",
      "0        2       3  12669  9656     7561     214              2674   \n",
      "1        2       3   7057  9810     9568    1762              3293   \n",
      "2        2       3   6353  8808     7684    2405              3516   \n",
      "3        1       3  13265  1196     4221    6404               507   \n",
      "4        2       3  22615  5410     7198    3915              1777   \n",
      "\n",
      "   Delicassen  labels  Label  labels_DBSCAN  \n",
      "0        1338       3      0              0  \n",
      "1        1776       0      0              0  \n",
      "2        7844       0      0             -1  \n",
      "3        1788       3      0              0  \n",
      "4        5185       1      0             -1  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN \n",
    "\n",
    "dbscan = DBSCAN(eps=0.5)\n",
    "\n",
    "dbscan.fit(customers_scale)\n",
    "\n",
    "df['labels_DBSCAN'] = dbscan.labels_\n",
    "\n",
    "print(\"\\nDatos originales con etiquetas de clúster DBSCAN:\")\n",
    "print(df.head())\n",
    "\n",
    "# Los pongo en un csv para que sea más legible\n",
    "df.to_csv('customer_preferences_with_dbscan_labels.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuenta los valores en `labels_DBSCAN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels_DBSCAN\n",
       " 0    261\n",
       "-1    174\n",
       " 1      5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts = df['labels_DBSCAN'].value_counts()\n",
    "label_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto 6 - Comparar K-Means con DBSCAN\n",
    "\n",
    "Ahora queremos comparar visualmente cómo K-Means y DBSCAN han agrupado nuestros datos. Crearemos gráficos de dispersión para varias columnas. Para cada uno de los siguientes pares de columnas, traza un gráfico de dispersión utilizando `labels` y otro utilizando `labels_DBSCAN`. Ponlos uno al lado del otro para compararlos. ¿Qué algoritmo de agrupación tiene más sentido?\n",
    "\n",
    "Columnas a visualizar:\n",
    "\n",
    "* `Detergents_Paper` as X and `Milk` as y\n",
    "* `Grocery` as X and `Fresh` as y\n",
    "* `Frozen` as X and `Delicassen` as y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualice `Detergentes_Papel` como X y `Leche` como Y mediante `labels` y `labels_DBSCAN` respectivamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x,y,hue):\n",
    "    sns.scatterplot(x=x, \n",
    "                    y=y,\n",
    "                    hue=hue)\n",
    "    plt.title('Detergents Paper vs Milk ')\n",
    "    return plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualice `Grocery` como X y `Fresh` como Y mediante `labels` y `labels_DBSCAN` respectivamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualice `Frozen` como X y `Delicassen` como Y mediante `labels` y `labels_DBSCAN` respectivamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a utilizar un groupby para ver cómo la media difiere entre los grupos. Agrupamos `customers` por `labels` y `labels_DBSCAN` respectivamente y calculamos las medias de todas las columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué algoritmo funciona mejor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tus observaciones aquí**\n",
    "\n",
    "El rendimiento de los algoritmos..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge 2 - Cambiar el número de clusters de K-Means\n",
    "\n",
    "Como hemos mencionado antes, no tenemos que preocuparnos por el número de clusters con DBSCAN porque lo decide automáticamente en función de los parámetros que le enviemos. Pero con K-Means, tenemos que suministrar el parámetro `n_clusters` (si no se suministra `n_clusters`, el algoritmo utilizará `8` por defecto). Debe saber que el número óptimo de clusters varía en función del conjunto de datos. K-Means puede funcionar mal si se utiliza un número incorrecto de clusters.\n",
    "\n",
    "En el aprendizaje automático avanzado, los científicos de datos prueban diferentes números de clusters y evalúan los resultados con medidas estadísticas (leer [aquí](https://en.wikipedia.org/wiki/Cluster_analysis#External_evaluation)). Hoy no vamos a utilizar medidas estadísticas, sino nuestros ojos. En las celdas de abajo, experimenta con distintos números de conglomerados y visualízalos con gráficos de dispersión. ¿Qué número de clusters parece funcionar mejor para K-Means?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tus observaciones aquí**\n",
    "\n",
    "* Viendo los gráficos del k-means ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge 3 - Cambiar `eps` y `min_samples` de DBSCAN\n",
    "\n",
    "Experimenta cambiando los parámetros `eps` y `min_samples` de DBSCAN. Mira cómo difieren los resultados con la visualización de gráficos de dispersión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tus observaciones aquí**\n",
    "\n",
    "    + El DBscan ajustado...\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
